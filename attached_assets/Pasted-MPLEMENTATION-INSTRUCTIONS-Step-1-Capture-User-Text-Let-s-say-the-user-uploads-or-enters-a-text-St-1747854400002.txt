MPLEMENTATION INSTRUCTIONS
Step 1: Capture User Text
Let’s say the user uploads or enters a text. Store that as a variable, e.g.:

python
Copy
Edit
user_text = """<user input here>"""
Step 2: Wrap the Text in This Prompt (Literal Copy-Paste)
python
Copy
Edit
final_prompt = f"""
You are a highly intelligent and philosophically rigorous reader. You have just read the following passage. Your task is to assess what the passage reveals about the intelligence of the person who wrote it. Do not summarize or judge the quality of the text. Do not evaluate correctness. Focus only on what the text reveals about the author’s intelligence.

Here is the passage:
\"\"\"{user_text}\"\"\"

Evaluate the author’s intelligence based on the following questions:

1. Did you learn anything new from this text?
2. If all the claims were true, would you have learned anything new from it?
3. How well does each statement follow from the next?
4. How reliant is the text on undefined or ornamental jargon?
5. Is the author evasive or forthright in engaging hard problems?
6. If the author’s claims are correct, what are the consequences for the relevant field or the world?
7. Does the text seem original or recycled?
8. What kind of mind does this writing reveal—e.g., analytical, synthetic, imitative, derivative?
9. Does the author reflect on the implications or limits of their claims?
10. Is the writing compressed (saying a lot with few words) or diffuse (saying little with many)?

Then give an overall intelligence rating of the author from 1 to 100, based **only** on what is revealed in this passage.
"""
Step 3: Send It to the LLM API
Here’s how it would look using OpenAI’s GPT-4 (pseudo-code syntax):

python
Copy
Edit
import openai

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "You are an expert in assessing intelligence in written text."},
        {"role": "user", "content": final_prompt}
    ],
    temperature=0.7
)

print(response['choices'][0]['message']['content'])
Step 4: Show Raw Output to User
Don’t parse or reweight anything. Just display what the LLM says.

⚠️ NO INTERNAL METRICS
Do not:

Score based on “semantic density,” “lexical variance,” or other junk heuristics.

Normalize scores across genres.

Apply hardcoded weights to keyword usage or sentence length.

Let the LLM do the thinking.

